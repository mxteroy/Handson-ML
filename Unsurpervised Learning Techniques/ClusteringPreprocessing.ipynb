{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using clustering for preprocessing\n",
    "- can be efficient in dimensioality reduction for supervised learning algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_digits, y_digits = load_digits(return_X_y=True) #return_X_y return data and target as a tuple instead of a Bunch\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_digits, y_digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jameseroy/ml/env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9711111111111111"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train, y_train)\n",
    "log_reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# although I can say that 10 cluster is enough because there are 10 digits (one cluster per digit), each digits is written differently so choose 50 to be safe\n",
    "kmeans = KMeans(n_clusters=50) \n",
    "\n",
    "'''\n",
    "steps of pipeline:\n",
    "- cluster the input into 50 clusters\n",
    "- replace the images with their disances to these 50 clusters\n",
    "- apply the regression model\n",
    "'''\n",
    "pipeline = Pipeline([\n",
    "    (\"kmeans\", KMeans(n_clusters=50)),\n",
    "    (\"log_reg\", LogisticRegression(max_iter=100000))\n",
    "])\n",
    "pipeline.fit(X_train, y_train)\n",
    "pipeline.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A little bit better than the with dimensionality reduction, but that was chosen as a guess\n",
    "\n",
    "#### Using GridSearchCV to find the optimal number of clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 98 candidates, totalling 294 fits\n",
      "[CV] END ...............................kmeans__n_clusters=2; total time=   0.5s\n",
      "[CV] END ...............................kmeans__n_clusters=2; total time=   0.7s\n",
      "[CV] END ...............................kmeans__n_clusters=2; total time=   0.6s\n",
      "[CV] END ...............................kmeans__n_clusters=3; total time=   1.4s\n",
      "[CV] END ...............................kmeans__n_clusters=3; total time=   0.9s\n",
      "[CV] END ...............................kmeans__n_clusters=3; total time=   1.1s\n",
      "[CV] END ...............................kmeans__n_clusters=4; total time=   1.8s\n",
      "[CV] END ...............................kmeans__n_clusters=4; total time=   1.8s\n",
      "[CV] END ...............................kmeans__n_clusters=4; total time=   1.6s\n",
      "[CV] END ...............................kmeans__n_clusters=5; total time=   3.2s\n",
      "[CV] END ...............................kmeans__n_clusters=5; total time=   2.3s\n",
      "[CV] END ...............................kmeans__n_clusters=5; total time=   2.8s\n",
      "[CV] END ...............................kmeans__n_clusters=6; total time=   4.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jameseroy/ml/env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...............................kmeans__n_clusters=6; total time=   5.6s\n",
      "[CV] END ...............................kmeans__n_clusters=6; total time=   3.1s\n",
      "[CV] END ...............................kmeans__n_clusters=7; total time=   4.9s\n",
      "[CV] END ...............................kmeans__n_clusters=7; total time=   5.4s\n",
      "[CV] END ...............................kmeans__n_clusters=7; total time=   3.2s\n",
      "[CV] END ...............................kmeans__n_clusters=8; total time=   4.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jameseroy/ml/env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...............................kmeans__n_clusters=8; total time=   5.6s\n",
      "[CV] END ...............................kmeans__n_clusters=8; total time=   2.6s\n",
      "[CV] END ...............................kmeans__n_clusters=9; total time=   4.8s\n",
      "[CV] END ...............................kmeans__n_clusters=9; total time=   4.5s\n",
      "[CV] END ...............................kmeans__n_clusters=9; total time=   2.9s\n",
      "[CV] END ..............................kmeans__n_clusters=10; total time=   5.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jameseroy/ml/env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................kmeans__n_clusters=10; total time=   5.7s\n",
      "[CV] END ..............................kmeans__n_clusters=10; total time=   3.1s\n",
      "[CV] END ..............................kmeans__n_clusters=11; total time=   4.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jameseroy/ml/env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................kmeans__n_clusters=11; total time=   5.7s\n",
      "[CV] END ..............................kmeans__n_clusters=11; total time=   3.8s\n",
      "[CV] END ..............................kmeans__n_clusters=12; total time=   3.4s\n",
      "[CV] END ..............................kmeans__n_clusters=12; total time=   4.4s\n",
      "[CV] END ..............................kmeans__n_clusters=12; total time=   2.7s\n",
      "[CV] END ..............................kmeans__n_clusters=13; total time=   5.5s\n",
      "[CV] END ..............................kmeans__n_clusters=13; total time=   5.8s\n",
      "[CV] END ..............................kmeans__n_clusters=13; total time=   1.7s\n",
      "[CV] END ..............................kmeans__n_clusters=14; total time=   5.5s\n",
      "[CV] END ..............................kmeans__n_clusters=14; total time=   4.9s\n",
      "[CV] END ..............................kmeans__n_clusters=14; total time=   3.1s\n",
      "[CV] END ..............................kmeans__n_clusters=15; total time=   4.3s\n",
      "[CV] END ..............................kmeans__n_clusters=15; total time=   3.9s\n",
      "[CV] END ..............................kmeans__n_clusters=15; total time=   4.9s\n",
      "[CV] END ..............................kmeans__n_clusters=16; total time=   3.7s\n",
      "[CV] END ..............................kmeans__n_clusters=16; total time=   4.0s\n",
      "[CV] END ..............................kmeans__n_clusters=16; total time=   4.7s\n",
      "[CV] END ..............................kmeans__n_clusters=17; total time=   4.5s\n",
      "[CV] END ..............................kmeans__n_clusters=17; total time=   4.1s\n",
      "[CV] END ..............................kmeans__n_clusters=17; total time=   3.3s\n",
      "[CV] END ..............................kmeans__n_clusters=18; total time=   3.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jameseroy/ml/env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................kmeans__n_clusters=18; total time=   6.0s\n",
      "[CV] END ..............................kmeans__n_clusters=18; total time=   3.1s\n",
      "[CV] END ..............................kmeans__n_clusters=19; total time=   4.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jameseroy/ml/env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................kmeans__n_clusters=19; total time=   6.3s\n",
      "[CV] END ..............................kmeans__n_clusters=19; total time=   5.4s\n",
      "[CV] END ..............................kmeans__n_clusters=20; total time=   3.8s\n",
      "[CV] END ..............................kmeans__n_clusters=20; total time=   5.1s\n",
      "[CV] END ..............................kmeans__n_clusters=20; total time=   4.1s\n",
      "[CV] END ..............................kmeans__n_clusters=21; total time=   3.5s\n",
      "[CV] END ..............................kmeans__n_clusters=21; total time=   5.0s\n",
      "[CV] END ..............................kmeans__n_clusters=21; total time=   2.8s\n",
      "[CV] END ..............................kmeans__n_clusters=22; total time=   4.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jameseroy/ml/env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................kmeans__n_clusters=22; total time=   6.1s\n",
      "[CV] END ..............................kmeans__n_clusters=22; total time=   4.9s\n",
      "[CV] END ..............................kmeans__n_clusters=23; total time=   2.3s\n",
      "[CV] END ..............................kmeans__n_clusters=23; total time=   5.9s\n",
      "[CV] END ..............................kmeans__n_clusters=23; total time=   3.2s\n",
      "[CV] END ..............................kmeans__n_clusters=24; total time=   4.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jameseroy/ml/env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................kmeans__n_clusters=24; total time=   6.3s\n",
      "[CV] END ..............................kmeans__n_clusters=24; total time=   4.3s\n",
      "[CV] END ..............................kmeans__n_clusters=25; total time=   2.7s\n",
      "[CV] END ..............................kmeans__n_clusters=25; total time=   5.4s\n",
      "[CV] END ..............................kmeans__n_clusters=25; total time=   3.4s\n",
      "[CV] END ..............................kmeans__n_clusters=26; total time=   2.6s\n",
      "[CV] END ..............................kmeans__n_clusters=26; total time=   5.6s\n",
      "[CV] END ..............................kmeans__n_clusters=26; total time=   5.2s\n",
      "[CV] END ..............................kmeans__n_clusters=27; total time=   3.3s\n",
      "[CV] END ..............................kmeans__n_clusters=27; total time=   5.2s\n",
      "[CV] END ..............................kmeans__n_clusters=27; total time=   4.7s\n",
      "[CV] END ..............................kmeans__n_clusters=28; total time=   2.9s\n",
      "[CV] END ..............................kmeans__n_clusters=28; total time=   5.8s\n",
      "[CV] END ..............................kmeans__n_clusters=28; total time=   2.4s\n",
      "[CV] END ..............................kmeans__n_clusters=29; total time=   4.9s\n",
      "[CV] END ..............................kmeans__n_clusters=29; total time=   3.7s\n",
      "[CV] END ..............................kmeans__n_clusters=29; total time=   2.5s\n",
      "[CV] END ..............................kmeans__n_clusters=30; total time=   4.6s\n",
      "[CV] END ..............................kmeans__n_clusters=30; total time=   7.4s\n",
      "[CV] END ..............................kmeans__n_clusters=30; total time=   4.1s\n",
      "[CV] END ..............................kmeans__n_clusters=31; total time=   3.8s\n",
      "[CV] END ..............................kmeans__n_clusters=31; total time=  10.0s\n",
      "[CV] END ..............................kmeans__n_clusters=31; total time=  10.2s\n",
      "[CV] END ..............................kmeans__n_clusters=32; total time=   5.2s\n",
      "[CV] END ..............................kmeans__n_clusters=32; total time=   7.5s\n",
      "[CV] END ..............................kmeans__n_clusters=32; total time=   6.6s\n",
      "[CV] END ..............................kmeans__n_clusters=33; total time=   4.0s\n",
      "[CV] END ..............................kmeans__n_clusters=33; total time=   5.8s\n",
      "[CV] END ..............................kmeans__n_clusters=33; total time=   5.7s\n",
      "[CV] END ..............................kmeans__n_clusters=34; total time=   6.1s\n",
      "[CV] END ..............................kmeans__n_clusters=34; total time=   6.9s\n",
      "[CV] END ..............................kmeans__n_clusters=34; total time=   7.0s\n",
      "[CV] END ..............................kmeans__n_clusters=35; total time=   6.9s\n",
      "[CV] END ..............................kmeans__n_clusters=35; total time=   5.6s\n",
      "[CV] END ..............................kmeans__n_clusters=35; total time=   8.3s\n",
      "[CV] END ..............................kmeans__n_clusters=36; total time=   7.5s\n",
      "[CV] END ..............................kmeans__n_clusters=36; total time=   5.8s\n",
      "[CV] END ..............................kmeans__n_clusters=36; total time=   4.0s\n",
      "[CV] END ..............................kmeans__n_clusters=37; total time=   5.2s\n",
      "[CV] END ..............................kmeans__n_clusters=37; total time=   5.6s\n",
      "[CV] END ..............................kmeans__n_clusters=37; total time=   5.3s\n",
      "[CV] END ..............................kmeans__n_clusters=38; total time=  10.8s\n",
      "[CV] END ..............................kmeans__n_clusters=38; total time=   4.9s\n",
      "[CV] END ..............................kmeans__n_clusters=38; total time=   4.5s\n",
      "[CV] END ..............................kmeans__n_clusters=39; total time=   3.9s\n",
      "[CV] END ..............................kmeans__n_clusters=39; total time=   5.9s\n",
      "[CV] END ..............................kmeans__n_clusters=39; total time=   4.2s\n",
      "[CV] END ..............................kmeans__n_clusters=40; total time=   4.8s\n",
      "[CV] END ..............................kmeans__n_clusters=40; total time=   8.3s\n",
      "[CV] END ..............................kmeans__n_clusters=40; total time=   3.9s\n",
      "[CV] END ..............................kmeans__n_clusters=41; total time=   3.8s\n",
      "[CV] END ..............................kmeans__n_clusters=41; total time=   8.0s\n",
      "[CV] END ..............................kmeans__n_clusters=41; total time=   6.5s\n",
      "[CV] END ..............................kmeans__n_clusters=42; total time=   5.1s\n",
      "[CV] END ..............................kmeans__n_clusters=42; total time=   8.4s\n",
      "[CV] END ..............................kmeans__n_clusters=42; total time=   6.3s\n",
      "[CV] END ..............................kmeans__n_clusters=43; total time=   6.5s\n",
      "[CV] END ..............................kmeans__n_clusters=43; total time=   4.3s\n",
      "[CV] END ..............................kmeans__n_clusters=43; total time=   6.8s\n",
      "[CV] END ..............................kmeans__n_clusters=44; total time=   6.3s\n",
      "[CV] END ..............................kmeans__n_clusters=44; total time=   6.1s\n",
      "[CV] END ..............................kmeans__n_clusters=44; total time=   9.7s\n",
      "[CV] END ..............................kmeans__n_clusters=45; total time=   5.5s\n",
      "[CV] END ..............................kmeans__n_clusters=45; total time=   4.3s\n",
      "[CV] END ..............................kmeans__n_clusters=45; total time=   9.6s\n",
      "[CV] END ..............................kmeans__n_clusters=46; total time=   5.6s\n",
      "[CV] END ..............................kmeans__n_clusters=46; total time=   4.1s\n",
      "[CV] END ..............................kmeans__n_clusters=46; total time=   4.3s\n",
      "[CV] END ..............................kmeans__n_clusters=47; total time=   4.8s\n",
      "[CV] END ..............................kmeans__n_clusters=47; total time=   9.0s\n",
      "[CV] END ..............................kmeans__n_clusters=47; total time=   6.8s\n",
      "[CV] END ..............................kmeans__n_clusters=48; total time=   6.6s\n",
      "[CV] END ..............................kmeans__n_clusters=48; total time=   6.7s\n",
      "[CV] END ..............................kmeans__n_clusters=48; total time=   4.9s\n",
      "[CV] END ..............................kmeans__n_clusters=49; total time=   4.7s\n",
      "[CV] END ..............................kmeans__n_clusters=49; total time=   6.9s\n",
      "[CV] END ..............................kmeans__n_clusters=49; total time=   4.2s\n",
      "[CV] END ..............................kmeans__n_clusters=50; total time=   5.1s\n",
      "[CV] END ..............................kmeans__n_clusters=50; total time=   4.1s\n",
      "[CV] END ..............................kmeans__n_clusters=50; total time=   5.4s\n",
      "[CV] END ..............................kmeans__n_clusters=51; total time=   4.1s\n",
      "[CV] END ..............................kmeans__n_clusters=51; total time=   6.7s\n",
      "[CV] END ..............................kmeans__n_clusters=51; total time=   6.8s\n",
      "[CV] END ..............................kmeans__n_clusters=52; total time=   3.9s\n",
      "[CV] END ..............................kmeans__n_clusters=52; total time=   6.9s\n",
      "[CV] END ..............................kmeans__n_clusters=52; total time=   4.4s\n",
      "[CV] END ..............................kmeans__n_clusters=53; total time=   3.9s\n",
      "[CV] END ..............................kmeans__n_clusters=53; total time=   5.5s\n",
      "[CV] END ..............................kmeans__n_clusters=53; total time=   3.0s\n",
      "[CV] END ..............................kmeans__n_clusters=54; total time=   2.7s\n",
      "[CV] END ..............................kmeans__n_clusters=54; total time=   4.4s\n",
      "[CV] END ..............................kmeans__n_clusters=54; total time=   5.4s\n",
      "[CV] END ..............................kmeans__n_clusters=55; total time=   5.2s\n",
      "[CV] END ..............................kmeans__n_clusters=55; total time=   6.6s\n",
      "[CV] END ..............................kmeans__n_clusters=55; total time=   5.7s\n",
      "[CV] END ..............................kmeans__n_clusters=56; total time=   4.6s\n",
      "[CV] END ..............................kmeans__n_clusters=56; total time=   5.6s\n",
      "[CV] END ..............................kmeans__n_clusters=56; total time=   6.4s\n",
      "[CV] END ..............................kmeans__n_clusters=57; total time=   5.4s\n",
      "[CV] END ..............................kmeans__n_clusters=57; total time=   5.3s\n",
      "[CV] END ..............................kmeans__n_clusters=57; total time=   6.3s\n",
      "[CV] END ..............................kmeans__n_clusters=58; total time=   5.4s\n",
      "[CV] END ..............................kmeans__n_clusters=58; total time=   6.1s\n",
      "[CV] END ..............................kmeans__n_clusters=58; total time=   6.9s\n",
      "[CV] END ..............................kmeans__n_clusters=59; total time=   6.0s\n",
      "[CV] END ..............................kmeans__n_clusters=59; total time=  11.2s\n",
      "[CV] END ..............................kmeans__n_clusters=59; total time=   5.9s\n",
      "[CV] END ..............................kmeans__n_clusters=60; total time=   6.2s\n",
      "[CV] END ..............................kmeans__n_clusters=60; total time=   7.3s\n",
      "[CV] END ..............................kmeans__n_clusters=60; total time=   4.4s\n",
      "[CV] END ..............................kmeans__n_clusters=61; total time=   6.3s\n",
      "[CV] END ..............................kmeans__n_clusters=61; total time=   4.3s\n",
      "[CV] END ..............................kmeans__n_clusters=61; total time=   4.2s\n",
      "[CV] END ..............................kmeans__n_clusters=62; total time=   4.9s\n",
      "[CV] END ..............................kmeans__n_clusters=62; total time=   4.7s\n",
      "[CV] END ..............................kmeans__n_clusters=62; total time=   5.5s\n",
      "[CV] END ..............................kmeans__n_clusters=63; total time=   6.0s\n",
      "[CV] END ..............................kmeans__n_clusters=63; total time=   8.6s\n",
      "[CV] END ..............................kmeans__n_clusters=63; total time=   3.6s\n",
      "[CV] END ..............................kmeans__n_clusters=64; total time=   4.1s\n",
      "[CV] END ..............................kmeans__n_clusters=64; total time=   5.8s\n",
      "[CV] END ..............................kmeans__n_clusters=64; total time=   5.2s\n",
      "[CV] END ..............................kmeans__n_clusters=65; total time=   4.3s\n",
      "[CV] END ..............................kmeans__n_clusters=65; total time=   7.5s\n",
      "[CV] END ..............................kmeans__n_clusters=65; total time=   5.2s\n",
      "[CV] END ..............................kmeans__n_clusters=66; total time=   4.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jameseroy/ml/env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............................kmeans__n_clusters=66; total time=  13.1s\n",
      "[CV] END ..............................kmeans__n_clusters=66; total time=   4.4s\n",
      "[CV] END ..............................kmeans__n_clusters=67; total time=   6.6s\n",
      "[CV] END ..............................kmeans__n_clusters=67; total time=   4.7s\n",
      "[CV] END ..............................kmeans__n_clusters=67; total time=   5.2s\n",
      "[CV] END ..............................kmeans__n_clusters=68; total time=   2.9s\n",
      "[CV] END ..............................kmeans__n_clusters=68; total time=   6.2s\n",
      "[CV] END ..............................kmeans__n_clusters=68; total time=   3.2s\n",
      "[CV] END ..............................kmeans__n_clusters=69; total time=   8.8s\n",
      "[CV] END ..............................kmeans__n_clusters=69; total time=   6.0s\n",
      "[CV] END ..............................kmeans__n_clusters=69; total time=   3.3s\n",
      "[CV] END ..............................kmeans__n_clusters=70; total time=   5.1s\n",
      "[CV] END ..............................kmeans__n_clusters=70; total time=   5.0s\n",
      "[CV] END ..............................kmeans__n_clusters=70; total time=   6.5s\n",
      "[CV] END ..............................kmeans__n_clusters=71; total time=   5.4s\n",
      "[CV] END ..............................kmeans__n_clusters=71; total time=   4.7s\n",
      "[CV] END ..............................kmeans__n_clusters=71; total time=   3.2s\n",
      "[CV] END ..............................kmeans__n_clusters=72; total time=   5.8s\n",
      "[CV] END ..............................kmeans__n_clusters=72; total time=   6.6s\n",
      "[CV] END ..............................kmeans__n_clusters=72; total time=   5.0s\n",
      "[CV] END ..............................kmeans__n_clusters=73; total time=   4.0s\n",
      "[CV] END ..............................kmeans__n_clusters=73; total time=   9.7s\n",
      "[CV] END ..............................kmeans__n_clusters=73; total time=   5.7s\n",
      "[CV] END ..............................kmeans__n_clusters=74; total time=   4.3s\n",
      "[CV] END ..............................kmeans__n_clusters=74; total time=   5.0s\n",
      "[CV] END ..............................kmeans__n_clusters=74; total time=   7.2s\n",
      "[CV] END ..............................kmeans__n_clusters=75; total time=   6.7s\n",
      "[CV] END ..............................kmeans__n_clusters=75; total time=   8.2s\n",
      "[CV] END ..............................kmeans__n_clusters=75; total time=   5.3s\n",
      "[CV] END ..............................kmeans__n_clusters=76; total time=   4.6s\n",
      "[CV] END ..............................kmeans__n_clusters=76; total time=   6.6s\n",
      "[CV] END ..............................kmeans__n_clusters=76; total time=   3.9s\n",
      "[CV] END ..............................kmeans__n_clusters=77; total time=   3.2s\n",
      "[CV] END ..............................kmeans__n_clusters=77; total time=   5.0s\n",
      "[CV] END ..............................kmeans__n_clusters=77; total time=   5.4s\n",
      "[CV] END ..............................kmeans__n_clusters=78; total time=   3.1s\n",
      "[CV] END ..............................kmeans__n_clusters=78; total time=   3.3s\n",
      "[CV] END ..............................kmeans__n_clusters=78; total time=   3.3s\n",
      "[CV] END ..............................kmeans__n_clusters=79; total time=   2.9s\n",
      "[CV] END ..............................kmeans__n_clusters=79; total time=   4.5s\n",
      "[CV] END ..............................kmeans__n_clusters=79; total time=   3.1s\n",
      "[CV] END ..............................kmeans__n_clusters=80; total time=   3.8s\n",
      "[CV] END ..............................kmeans__n_clusters=80; total time=   3.9s\n",
      "[CV] END ..............................kmeans__n_clusters=80; total time=   5.7s\n",
      "[CV] END ..............................kmeans__n_clusters=81; total time=   4.5s\n",
      "[CV] END ..............................kmeans__n_clusters=81; total time=   5.4s\n",
      "[CV] END ..............................kmeans__n_clusters=81; total time=   3.5s\n",
      "[CV] END ..............................kmeans__n_clusters=82; total time=   9.7s\n",
      "[CV] END ..............................kmeans__n_clusters=82; total time=   5.2s\n",
      "[CV] END ..............................kmeans__n_clusters=82; total time=   3.6s\n",
      "[CV] END ..............................kmeans__n_clusters=83; total time=   3.4s\n",
      "[CV] END ..............................kmeans__n_clusters=83; total time=   3.8s\n",
      "[CV] END ..............................kmeans__n_clusters=83; total time=   3.5s\n",
      "[CV] END ..............................kmeans__n_clusters=84; total time=   5.1s\n",
      "[CV] END ..............................kmeans__n_clusters=84; total time=   6.4s\n",
      "[CV] END ..............................kmeans__n_clusters=84; total time=   4.1s\n",
      "[CV] END ..............................kmeans__n_clusters=85; total time=   5.0s\n",
      "[CV] END ..............................kmeans__n_clusters=85; total time=   4.3s\n",
      "[CV] END ..............................kmeans__n_clusters=85; total time=   4.4s\n",
      "[CV] END ..............................kmeans__n_clusters=86; total time=   3.2s\n",
      "[CV] END ..............................kmeans__n_clusters=86; total time=   6.0s\n",
      "[CV] END ..............................kmeans__n_clusters=86; total time=   7.7s\n",
      "[CV] END ..............................kmeans__n_clusters=87; total time=   3.1s\n",
      "[CV] END ..............................kmeans__n_clusters=87; total time=   4.6s\n",
      "[CV] END ..............................kmeans__n_clusters=87; total time=   6.5s\n",
      "[CV] END ..............................kmeans__n_clusters=88; total time=   6.4s\n",
      "[CV] END ..............................kmeans__n_clusters=88; total time=   6.4s\n",
      "[CV] END ..............................kmeans__n_clusters=88; total time=   5.7s\n",
      "[CV] END ..............................kmeans__n_clusters=89; total time=   3.7s\n",
      "[CV] END ..............................kmeans__n_clusters=89; total time=   5.9s\n",
      "[CV] END ..............................kmeans__n_clusters=89; total time=   3.8s\n",
      "[CV] END ..............................kmeans__n_clusters=90; total time=   3.3s\n",
      "[CV] END ..............................kmeans__n_clusters=90; total time=   3.7s\n",
      "[CV] END ..............................kmeans__n_clusters=90; total time=   6.4s\n",
      "[CV] END ..............................kmeans__n_clusters=91; total time=   4.3s\n",
      "[CV] END ..............................kmeans__n_clusters=91; total time=   5.5s\n",
      "[CV] END ..............................kmeans__n_clusters=91; total time=   7.4s\n",
      "[CV] END ..............................kmeans__n_clusters=92; total time=   5.1s\n",
      "[CV] END ..............................kmeans__n_clusters=92; total time=   6.1s\n",
      "[CV] END ..............................kmeans__n_clusters=92; total time=   3.6s\n",
      "[CV] END ..............................kmeans__n_clusters=93; total time=   3.6s\n",
      "[CV] END ..............................kmeans__n_clusters=93; total time=   3.6s\n",
      "[CV] END ..............................kmeans__n_clusters=93; total time=   3.4s\n",
      "[CV] END ..............................kmeans__n_clusters=94; total time=   4.3s\n",
      "[CV] END ..............................kmeans__n_clusters=94; total time=   5.7s\n",
      "[CV] END ..............................kmeans__n_clusters=94; total time=   3.5s\n",
      "[CV] END ..............................kmeans__n_clusters=95; total time=   7.4s\n",
      "[CV] END ..............................kmeans__n_clusters=95; total time=  10.4s\n",
      "[CV] END ..............................kmeans__n_clusters=95; total time=   3.8s\n",
      "[CV] END ..............................kmeans__n_clusters=96; total time=   3.2s\n",
      "[CV] END ..............................kmeans__n_clusters=96; total time=   5.4s\n",
      "[CV] END ..............................kmeans__n_clusters=96; total time=   3.5s\n",
      "[CV] END ..............................kmeans__n_clusters=97; total time=   6.0s\n",
      "[CV] END ..............................kmeans__n_clusters=97; total time=   3.9s\n",
      "[CV] END ..............................kmeans__n_clusters=97; total time=   4.2s\n",
      "[CV] END ..............................kmeans__n_clusters=98; total time=   3.5s\n",
      "[CV] END ..............................kmeans__n_clusters=98; total time=   4.3s\n",
      "[CV] END ..............................kmeans__n_clusters=98; total time=   9.4s\n",
      "[CV] END ..............................kmeans__n_clusters=99; total time=   3.4s\n",
      "[CV] END ..............................kmeans__n_clusters=99; total time=   5.7s\n",
      "[CV] END ..............................kmeans__n_clusters=99; total time=   4.0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[('kmeans', KMeans(n_clusters=50)),\n",
       "                                       ('log_reg',\n",
       "                                        LogisticRegression(max_iter=100000))]),\n",
       "             param_grid={'kmeans__n_clusters': range(2, 100)}, verbose=2)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = dict(kmeans__n_clusters=range(2,100))\n",
    "grid_search_clf = GridSearchCV(pipeline, param_grid, cv=3, verbose=2)\n",
    "grid_search_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('gridsearch_clf.sav', 'wb') as f:\n",
    "    pickle.dump(grid_search_clf, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = pickle.load(open('gridsearch_clf.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9777777777777777"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kmeans__n_clusters': 83}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9866666666666667"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    (\"kmeans\", KMeans(n_clusters=150)),\n",
    "    (\"log_reg\", LogisticRegression(max_iter=100000))\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "pipeline.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Clustering for Semi-Supervised Learning\n",
    "- When there are many unlabeled instances and few labeled instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8644444444444445"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_labeled = 50 # get 50 labeled instances from training set\n",
    "log_reg = LogisticRegression(max_iter=1000000)\n",
    "log_reg.fit(X_train[:n_labeled], y_train[:n_labeled])\n",
    "log_reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No surprise that the accuracy is worse because the training data is smaller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1347, 64) (1347, 50) (50,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "k = 50\n",
    "kmeans = KMeans(n_clusters=k) #50 clusters\n",
    "X_digits_dist = kmeans.fit_transform(X_train) # returns the distances of each instance to the 50 clusters\n",
    "# axis 0 = y-axis\n",
    "representative_digit_idx = np.argmin(X_digits_dist, axis=0) # get the image indexes closest to the centroids of each of the 50 clusters\n",
    "print(X_train.shape, X_digits_dist.shape, representative_digit_idx.shape)\n",
    "X_representative_digits = X_train[representative_digit_idx] #get those images from the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x144 with 50 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(20, 2))\n",
    "\n",
    "for index, X_representative_digit in enumerate(X_representative_digits):\n",
    "    plt.subplot(k//10, 10, index+1) # rows, cols, index\n",
    "    plt.imshow(X_representative_digit.reshape(8, 8), cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.axis('off')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_representative_digits = np.array([8, 1, 6, 4, 2, 0, 7, 8, 0, 1, 2, 9, 5, 3, 4, 6, 1, 5, 9, 7, 5, 2, 3, 5, 6, 8, 1, 4, 3, 7, 4, 3, 0, 2, 9, 4, 0, 8, 5, 7,\n",
    "                                   6, 2, 0, 8, 1, 9, 2, 3, 2, 2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jameseroy/ml/env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8955555555555555"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_representative_digits, y_representative_digits)\n",
    "log_reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Big jump in accuracy from 86.4%!!\n",
    "\n",
    "**Labeling data is tedious**. That is why it is better to just label to representative instances rather than just random instances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Label propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1347\n"
     ]
    }
   ],
   "source": [
    "print(len(kmeans.labels_))\n",
    "\n",
    "y_train_propagated = np.empty(len(X_train), dtype=np.int32)\n",
    "for i in range(k):\n",
    "    # kmeans.labels_ is the array of clusters that each corresponding ith instance belongs to\n",
    "    # kmeans.labels_ == i returns an array of booleans of size len(X_train)\n",
    "    y_train_propagated[kmeans.labels_ == i] = y_representative_digits[i] # convert the labels of each instance to their cluster's representative digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9133333333333333"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg = LogisticRegression(max_iter=100000)\n",
    "log_reg.fit(X_train, y_train_propagated)\n",
    "log_reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even better!\n",
    "\n",
    "Downsides:\n",
    "- instances that are close to the boundaries could have been mislabeled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Only propagate labels to 20% of the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2034149962880475\n"
     ]
    }
   ],
   "source": [
    "threshold = .2\n",
    "\n",
    "percent_propagated = 0\n",
    "\n",
    "y_train_propagated2 = np.copy(y_train)\n",
    "for i in range(k):\n",
    "    if percent_propagated > threshold:\n",
    "        break\n",
    "    y_train_propagated2[kmeans.labels_ == i] = y_representative_digits[i]\n",
    "    percent_propagated += sum(1 if label == 1 else 0 for label in kmeans.labels_ == i)/len(kmeans.labels_)\n",
    "    \n",
    "print(percent_propagated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9644444444444444"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg = LogisticRegression(max_iter=100000)\n",
    "log_reg.fit(X_train, y_train_propagated2)\n",
    "log_reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### the book's way of partial label propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentile_closest = 20\n",
    "\n",
    "X_cluster_dist = X_digits_dist[np.arange(len(X_train)), kmeans.labels_]\n",
    "for i in range(k):\n",
    "    in_cluster = (kmeans.labels_ == i)\n",
    "    cluster_dist = X_cluster_dist[in_cluster]\n",
    "    cutoff_distance = np.percentile(cluster_dist, percentile_closest)\n",
    "    above_cutoff = (X_cluster_dist > cutoff_distance)\n",
    "    X_cluster_dist[in_cluster & above_cutoff] = -1\n",
    "    \n",
    "partially_propagated = (X_cluster_dist != -1)\n",
    "X_train_partially_propagated = X_train[partially_propagated]\n",
    "y_train_partially_propagated = y_train_propagated[partially_propagated]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=5000, multi_class='ovr', random_state=42)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg = LogisticRegression(multi_class=\"ovr\", solver=\"lbfgs\", max_iter=5000, random_state=42)\n",
    "log_reg.fit(X_train_partially_propagated, y_train_partially_propagated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9088888888888889"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
