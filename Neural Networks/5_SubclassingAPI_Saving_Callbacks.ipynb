{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential API and Function API\n",
    "- They are declarative: I start by *declaring* which layers I want to use and how they should be connected, and only then I can start feeding in data for training or inference\n",
    "    - advantages\n",
    "        1. model can be easily saved, cloned, and shared\n",
    "        2. the structure of the network can be displayed and analyzed\n",
    "        3. the framework can infer shapes and check types, so errors can be caught early (before any data goes through the model)\n",
    "        4. fairly easy to debug, since the whole model is a static graph of layers\n",
    "    - disadvantages:\n",
    "        1. **static**\n",
    "        \n",
    "## Subclassing API\n",
    "- allows for dynamic behaviors (such as loops, varying shapes, conditional branching)\n",
    "- how to use: \n",
    "    1. subclass the *Model* class\n",
    "    2. create the layers needed in the constructor\n",
    "    3. perform computations in the *call()* method\n",
    "    \n",
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "class WideAndDeepModel(keras.Model):\n",
    "    def __init(self, units=30, activation=\"relu\", **kwargs):\n",
    "        super().__init(**kwargs) # handle the standard arguments (e.g. name)\n",
    "        self.hidden1 = keras.layers.Dense(units, activation=activation)\n",
    "        self.hidden2 = keras.layers.Dense(units, activation=activation)\n",
    "        self.main_output = keras.layers.Dense(1)\n",
    "        self.aux_output = keras.layers.Dense(1)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        input_A, input_B = inputs\n",
    "        hidden1 = self.hidden1(input_B)\n",
    "        hidden2 = self.hidden2(hidden1)\n",
    "        concat = keras.layers.concatenate([input_A, hidden2])\n",
    "        main_output = self.main_output(concat)\n",
    "        aux_output = self.aux_output(hidden2)\n",
    "        return main_output, aux_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = WideAndDeepModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Within the *call()* method, anything can be done from *for loops, if statements, lower-level TF operations, usage of the layers intialized in the constructor, and more!* Very useful for researchers working in bleeding edge ML. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downsides (b/c of the architecture being hidden w/in the *call()* method:\n",
    "- Models cannot be saved or cloned\n",
    "- *summary()* method only gives a list of layers without any information on their connections to each other\n",
    "- Keras cannot check types and shapes ahead of time\n",
    "- Keras cannot easily inspect it\n",
    "\n",
    "**Only use subclassing API when the flexibility is necessary like when doing research**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving and restoring a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            [(None, 8)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 30)           270         input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 30)           930         dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 38)           0           input_6[0][0]                    \n",
      "                                                                 dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 1)            39          concatenate_5[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 1,239\n",
      "Trainable params: 1,239\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#============SAMPLE MODEL================\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "\n",
    "X_train_full, X_test, y_test_full, y_test = train_test_split(housing.data, housing.target)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_test_full)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "from tensorflow.keras.layers import Input, Dense, Concatenate, concatenate\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "input_ = Input(shape=X_train.shape[1:]) \n",
    "hidden1 = Dense(30, activation=\"relu\")(input_) \n",
    "hidden2 = Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = Concatenate()([input_, hidden2]) \n",
    "output = Dense(1)(concat) \n",
    "model = Model(inputs=[input_], outputs=[output])\n",
    "\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=SGD(lr=1e-3), metrics=[\"accuracy\"])\n",
    "history=model.fit(X_train, y_train, epochs=30, validation_data=(X_val, y_val), verbose=0)\n",
    "model.summary()\n",
    "#========================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"sample_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the HDF5 format to save the model's architecture and values of all model parameteres for every layer. Saves the optimizer *SGD* (incl. its hyperparameters and any state it may have)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"sample_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            [(None, 8)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 30)           270         input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 30)           930         dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 38)           0           input_6[0][0]                    \n",
      "                                                                 dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 1)            39          concatenate_5[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 1,239\n",
      "Trainable params: 1,239\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Avoid training progress when training for hours\n",
    "- Save model at regular intervals so that training progress won't be completely lost if the computer crashes\n",
    "    - **use callbacks**\n",
    "    \n",
    "#### Using callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=SGD(lr=1e-3), metrics=[\"accuracy\"])\n",
    "checkpoint_cb = ModelCheckpoint(\"keras_model.h5\", save_best_only=True) # saves on every epoch by default. save_best_only = only save the model that performs best on valida set\n",
    "history = model.fit(X_train, y_train, epochs=20, callbacks=[checkpoint_cb], validation_data=(X_val, y_val), verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"keras_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            [(None, 8)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 30)           270         input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 30)           930         dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 38)           0           input_6[0][0]                    \n",
      "                                                                 dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 1)            39          concatenate_5[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 1,239\n",
      "Trainable params: 1,239\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine multiple callbacks to save ensure the model is saved at different points in time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_cb = EarlyStopping(patience=10, restore_best_weights=True) # rolls back to the best model found after a certain number of epochs w/ progress (defined by patience)\n",
    "history = model.fit(X_train, y_train, epochs=20, callbacks=[checkpoint_cb, early_stopping_cb], validation_data=(X_val, y_val), verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom callbacks for extra control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrintValRationCallback(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        print(\"\\nval/rain: {:.2f}\".format(logs[\"val_los\"] / logs[\"loss\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "other methods that can be implemented with custom callbacks:\n",
    "- for training - called by fit():\n",
    "    - on_train_begin()\n",
    "    - on_train_end()\n",
    "    - on_epoch_end()\n",
    "    - on_batch_begin()\n",
    "    - on_batch_end()\n",
    "- for evaluation - called by evaluate():\n",
    "    - on_test_begin()\n",
    "    - on_test_end()\n",
    "    - on_test_batch_begin()\n",
    "    - on_test_batch_end()\n",
    "- for prediction - called by predict():\n",
    "    - on_predict_begin()\n",
    "    - on_prdict_end()\n",
    "    - on_predict_batch_begin()\n",
    "    - on_predict_batch_end()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorBoard for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./my_logs/run_2021_04_24-19_32_59'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "\n",
    "root_logdir = os.path.join(os.curdir, \"my_logs\")\n",
    "\n",
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n",
    "get_run_logdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "363/363 [==============================] - 0s 928us/step - loss: 0.3806 - accuracy: 0.0028 - val_loss: 0.3616 - val_accuracy: 0.0028\n",
      "Epoch 2/30\n",
      "363/363 [==============================] - 0s 723us/step - loss: 0.3790 - accuracy: 0.0028 - val_loss: 0.3591 - val_accuracy: 0.0028\n",
      "Epoch 3/30\n",
      "363/363 [==============================] - 0s 704us/step - loss: 0.3782 - accuracy: 0.0028 - val_loss: 0.3579 - val_accuracy: 0.0028\n",
      "Epoch 4/30\n",
      "363/363 [==============================] - 0s 704us/step - loss: 0.3768 - accuracy: 0.0028 - val_loss: 0.3583 - val_accuracy: 0.0028\n",
      "Epoch 5/30\n",
      "363/363 [==============================] - 0s 754us/step - loss: 0.3759 - accuracy: 0.0028 - val_loss: 0.3566 - val_accuracy: 0.0028\n",
      "Epoch 6/30\n",
      "363/363 [==============================] - 0s 715us/step - loss: 0.3748 - accuracy: 0.0028 - val_loss: 0.3562 - val_accuracy: 0.0028\n",
      "Epoch 7/30\n",
      "363/363 [==============================] - 0s 711us/step - loss: 0.3743 - accuracy: 0.0028 - val_loss: 0.3545 - val_accuracy: 0.0028\n",
      "Epoch 8/30\n",
      "363/363 [==============================] - 0s 704us/step - loss: 0.3730 - accuracy: 0.0028 - val_loss: 0.3546 - val_accuracy: 0.0028\n",
      "Epoch 9/30\n",
      "363/363 [==============================] - 0s 717us/step - loss: 0.3720 - accuracy: 0.0028 - val_loss: 0.3526 - val_accuracy: 0.0028\n",
      "Epoch 10/30\n",
      "363/363 [==============================] - 0s 710us/step - loss: 0.3715 - accuracy: 0.0028 - val_loss: 0.3519 - val_accuracy: 0.0028\n",
      "Epoch 11/30\n",
      "363/363 [==============================] - 0s 711us/step - loss: 0.3705 - accuracy: 0.0028 - val_loss: 0.3526 - val_accuracy: 0.0028\n",
      "Epoch 12/30\n",
      "363/363 [==============================] - 0s 706us/step - loss: 0.3694 - accuracy: 0.0028 - val_loss: 0.3500 - val_accuracy: 0.0028\n",
      "Epoch 13/30\n",
      "363/363 [==============================] - 0s 724us/step - loss: 0.3684 - accuracy: 0.0028 - val_loss: 0.3513 - val_accuracy: 0.0028\n",
      "Epoch 14/30\n",
      "363/363 [==============================] - 0s 700us/step - loss: 0.3673 - accuracy: 0.0028 - val_loss: 0.3514 - val_accuracy: 0.0028\n",
      "Epoch 15/30\n",
      "363/363 [==============================] - 0s 727us/step - loss: 0.3670 - accuracy: 0.0028 - val_loss: 0.3470 - val_accuracy: 0.0028\n",
      "Epoch 16/30\n",
      "363/363 [==============================] - 0s 707us/step - loss: 0.3659 - accuracy: 0.0028 - val_loss: 0.3477 - val_accuracy: 0.0028\n",
      "Epoch 17/30\n",
      "363/363 [==============================] - 0s 702us/step - loss: 0.3648 - accuracy: 0.0028 - val_loss: 0.3458 - val_accuracy: 0.0028\n",
      "Epoch 18/30\n",
      "363/363 [==============================] - 0s 706us/step - loss: 0.3646 - accuracy: 0.0028 - val_loss: 0.3470 - val_accuracy: 0.0028\n",
      "Epoch 19/30\n",
      "363/363 [==============================] - 0s 713us/step - loss: 0.3634 - accuracy: 0.0028 - val_loss: 0.3462 - val_accuracy: 0.0028\n",
      "Epoch 20/30\n",
      "363/363 [==============================] - 0s 712us/step - loss: 0.3625 - accuracy: 0.0028 - val_loss: 0.3457 - val_accuracy: 0.0028\n",
      "Epoch 21/30\n",
      "363/363 [==============================] - 0s 708us/step - loss: 0.3623 - accuracy: 0.0028 - val_loss: 0.3438 - val_accuracy: 0.0028\n",
      "Epoch 22/30\n",
      "363/363 [==============================] - 0s 714us/step - loss: 0.3610 - accuracy: 0.0028 - val_loss: 0.3429 - val_accuracy: 0.0028\n",
      "Epoch 23/30\n",
      "363/363 [==============================] - 0s 714us/step - loss: 0.3600 - accuracy: 0.0028 - val_loss: 0.3442 - val_accuracy: 0.0028\n",
      "Epoch 24/30\n",
      "363/363 [==============================] - 0s 710us/step - loss: 0.3595 - accuracy: 0.0028 - val_loss: 0.3410 - val_accuracy: 0.0028\n",
      "Epoch 25/30\n",
      "363/363 [==============================] - 0s 731us/step - loss: 0.3585 - accuracy: 0.0028 - val_loss: 0.3420 - val_accuracy: 0.0028\n",
      "Epoch 26/30\n",
      "363/363 [==============================] - 0s 710us/step - loss: 0.3577 - accuracy: 0.0028 - val_loss: 0.3391 - val_accuracy: 0.0028\n",
      "Epoch 27/30\n",
      "363/363 [==============================] - 0s 714us/step - loss: 0.3580 - accuracy: 0.0028 - val_loss: 0.3400 - val_accuracy: 0.0028\n",
      "Epoch 28/30\n",
      "363/363 [==============================] - 0s 709us/step - loss: 0.3560 - accuracy: 0.0028 - val_loss: 0.3406 - val_accuracy: 0.0028\n",
      "Epoch 29/30\n",
      "363/363 [==============================] - 0s 712us/step - loss: 0.3560 - accuracy: 0.0028 - val_loss: 0.3394 - val_accuracy: 0.0028\n",
      "Epoch 30/30\n",
      "363/363 [==============================] - 0s 701us/step - loss: 0.3553 - accuracy: 0.0028 - val_loss: 0.3391 - val_accuracy: 0.0028\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "tensorboard_cb = TensorBoard(get_run_logdir())\n",
    "history = model.fit(X_train, y_train, epochs=30, validation_data=(X_val, y_val), callbacks=[tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my_logs/\n",
      "    run_2021_04_24-19_35_09/\n",
      "        train/\n",
      "            events.out.tfevents.1619310909.Jamess-MacBook-Pro-2.local.profile-empty\n",
      "            events.out.tfevents.1619310909.Jamess-MacBook-Pro-2.local.37118.280346.v2\n",
      "            plugins/\n",
      "                profile/\n",
      "                    2021_04_24_19_35_09/\n",
      "                        Jamess-MacBook-Pro-2.local.trace.json.gz\n",
      "                        Jamess-MacBook-Pro-2.local.xplane.pb\n",
      "                        Jamess-MacBook-Pro-2.local.overview_page.pb\n",
      "                        Jamess-MacBook-Pro-2.local.input_pipeline.pb\n",
      "                        Jamess-MacBook-Pro-2.local.memory_profile.json.gz\n",
      "                        Jamess-MacBook-Pro-2.local.kernel_stats.pb\n",
      "                        Jamess-MacBook-Pro-2.local.tensorflow_stats.pb\n",
      "        validation/\n",
      "            events.out.tfevents.1619310910.Jamess-MacBook-Pro-2.local.37118.281163.v2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def list_files(startpath):\n",
    "    for root, dirs, files in os.walk(startpath):\n",
    "        level = root.replace(startpath, '').count(os.sep)\n",
    "        indent = ' ' * 4 * (level)\n",
    "        print('{}{}/'.format(indent, os.path.basename(root)))\n",
    "        subindent = ' ' * 4 * (level + 1)\n",
    "        for f in files:\n",
    "            print('{}{}'.format(subindent, f))\n",
    "            \n",
    "list_files(\"my_logs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use SummaryWriter in tf.summary to log scalars, histograms, images, audio, and text which can all be visualized by tensorboard!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
