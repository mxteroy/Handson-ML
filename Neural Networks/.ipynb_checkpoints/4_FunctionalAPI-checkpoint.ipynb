{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functional API\n",
    "- enables building NNs with complex topologies, or with multiple inputs or outputs\n",
    "- non-sequential NNs\n",
    "\n",
    "### Non-sequenatial NNs\n",
    "- Wide & Deep NN\n",
    "    - connects part or all of the inputs directly to the output layer\n",
    "    - This architecture allows the network to learn deep pattern (w/ deep path) and simple rules (short path of input layer to output layer)\n",
    "    - In contrast: regular MLP forces all data to go through deep path (full stack of layers) which distorts simple patterns because of the sequence of transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "\n",
    "X_train_full, X_test, y_test_full, y_test = train_test_split(housing.data, housing.target)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_test_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, Concatenate, concatenate\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "input_ = Input(shape=X_train.shape[1:]) # input object. Models may have multiple inputs\n",
    "# dense hidden layer w/ 30 neurons. called like a function to pass in input_. Telling keras how to connect layers together. Hence \"Functional API\"\n",
    "hidden1 = Dense(30, activation=\"relu\")(input_) \n",
    "hidden2 = Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = Concatenate()([input_, hidden2]) # concatenate the input layer and hidden layer before the output layer\n",
    "output = Dense(1)(concat) # output layer with single layer and no activation function for regression\n",
    "model = Model(inputs=[input_], outputs=[output]) # instantiate the model w/ specifications for which inputs and outputs to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 3.1739 - accuracy: 0.0018 - val_loss: 0.7628 - val_accuracy: 0.0031\n",
      "Epoch 2/30\n",
      "363/363 [==============================] - 0s 693us/step - loss: 0.6958 - accuracy: 0.0037 - val_loss: 0.6805 - val_accuracy: 0.0031\n",
      "Epoch 3/30\n",
      "363/363 [==============================] - 0s 699us/step - loss: 0.6350 - accuracy: 0.0030 - val_loss: 0.6342 - val_accuracy: 0.0034\n",
      "Epoch 4/30\n",
      "363/363 [==============================] - 0s 700us/step - loss: 0.5810 - accuracy: 0.0034 - val_loss: 0.6145 - val_accuracy: 0.0034\n",
      "Epoch 5/30\n",
      "363/363 [==============================] - 0s 700us/step - loss: 0.5684 - accuracy: 0.0019 - val_loss: 0.5913 - val_accuracy: 0.0034\n",
      "Epoch 6/30\n",
      "363/363 [==============================] - 0s 699us/step - loss: 0.5382 - accuracy: 0.0044 - val_loss: 0.5751 - val_accuracy: 0.0034\n",
      "Epoch 7/30\n",
      "363/363 [==============================] - 0s 700us/step - loss: 0.5659 - accuracy: 0.0033 - val_loss: 0.5608 - val_accuracy: 0.0034\n",
      "Epoch 8/30\n",
      "363/363 [==============================] - 0s 698us/step - loss: 0.5255 - accuracy: 0.0034 - val_loss: 0.5484 - val_accuracy: 0.0034\n",
      "Epoch 9/30\n",
      "363/363 [==============================] - 0s 694us/step - loss: 0.5066 - accuracy: 0.0023 - val_loss: 0.5392 - val_accuracy: 0.0034\n",
      "Epoch 10/30\n",
      "363/363 [==============================] - 0s 697us/step - loss: 0.5174 - accuracy: 0.0033 - val_loss: 0.5273 - val_accuracy: 0.0034\n",
      "Epoch 11/30\n",
      "363/363 [==============================] - 0s 710us/step - loss: 0.4775 - accuracy: 0.0032 - val_loss: 0.5198 - val_accuracy: 0.0034\n",
      "Epoch 12/30\n",
      "363/363 [==============================] - 0s 706us/step - loss: 0.4917 - accuracy: 0.0035 - val_loss: 0.5105 - val_accuracy: 0.0034\n",
      "Epoch 13/30\n",
      "363/363 [==============================] - 0s 697us/step - loss: 0.4805 - accuracy: 0.0024 - val_loss: 0.5033 - val_accuracy: 0.0034\n",
      "Epoch 14/30\n",
      "363/363 [==============================] - 0s 714us/step - loss: 0.4822 - accuracy: 0.0028 - val_loss: 0.4972 - val_accuracy: 0.0034\n",
      "Epoch 15/30\n",
      "363/363 [==============================] - 0s 693us/step - loss: 0.4656 - accuracy: 0.0028 - val_loss: 0.4907 - val_accuracy: 0.0034\n",
      "Epoch 16/30\n",
      "363/363 [==============================] - 0s 705us/step - loss: 0.4699 - accuracy: 0.0030 - val_loss: 0.4860 - val_accuracy: 0.0034\n",
      "Epoch 17/30\n",
      "363/363 [==============================] - 0s 698us/step - loss: 0.4314 - accuracy: 0.0032 - val_loss: 0.4793 - val_accuracy: 0.0034\n",
      "Epoch 18/30\n",
      "363/363 [==============================] - 0s 699us/step - loss: 0.4336 - accuracy: 0.0045 - val_loss: 0.4742 - val_accuracy: 0.0034\n",
      "Epoch 19/30\n",
      "363/363 [==============================] - 0s 700us/step - loss: 0.4471 - accuracy: 0.0027 - val_loss: 0.4686 - val_accuracy: 0.0034\n",
      "Epoch 20/30\n",
      "363/363 [==============================] - 0s 700us/step - loss: 0.4445 - accuracy: 0.0032 - val_loss: 0.4667 - val_accuracy: 0.0034\n",
      "Epoch 21/30\n",
      "363/363 [==============================] - 0s 713us/step - loss: 0.4533 - accuracy: 0.0030 - val_loss: 0.4600 - val_accuracy: 0.0034\n",
      "Epoch 22/30\n",
      "363/363 [==============================] - 0s 708us/step - loss: 0.4342 - accuracy: 0.0023 - val_loss: 0.4565 - val_accuracy: 0.0034\n",
      "Epoch 23/30\n",
      "363/363 [==============================] - 0s 711us/step - loss: 0.4328 - accuracy: 0.0041 - val_loss: 0.4525 - val_accuracy: 0.0034\n",
      "Epoch 24/30\n",
      "363/363 [==============================] - 0s 731us/step - loss: 0.4295 - accuracy: 0.0019 - val_loss: 0.4484 - val_accuracy: 0.0034\n",
      "Epoch 25/30\n",
      "363/363 [==============================] - 0s 714us/step - loss: 0.4160 - accuracy: 0.0032 - val_loss: 0.4448 - val_accuracy: 0.0034\n",
      "Epoch 26/30\n",
      "363/363 [==============================] - 0s 705us/step - loss: 0.4146 - accuracy: 0.0030 - val_loss: 0.4421 - val_accuracy: 0.0034\n",
      "Epoch 27/30\n",
      "363/363 [==============================] - 0s 706us/step - loss: 0.4158 - accuracy: 0.0020 - val_loss: 0.4382 - val_accuracy: 0.0034\n",
      "Epoch 28/30\n",
      "363/363 [==============================] - 0s 704us/step - loss: 0.4186 - accuracy: 0.0036 - val_loss: 0.4359 - val_accuracy: 0.0034\n",
      "Epoch 29/30\n",
      "363/363 [==============================] - 0s 694us/step - loss: 0.4088 - accuracy: 0.0030 - val_loss: 0.4331 - val_accuracy: 0.0034\n",
      "Epoch 30/30\n",
      "363/363 [==============================] - 0s 693us/step - loss: 0.3980 - accuracy: 0.0025 - val_loss: 0.4313 - val_accuracy: 0.0034\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=SGD(lr=1e-3), metrics=[\"accuracy\"])\n",
    "\n",
    "history=model.fit(X_train, y_train, epochs=30, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if I want to send a subset of features through the wide path and a different subset through the deep path?\n",
    "- Solution: use multiple inputs (e.g. send 5 inputs through wide path, and 6 features trough deep path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_A = Input(shape=[5], name=\"wide_input\") # 5 features through wide path\n",
    "input_B = Input(shape=[6], name=\"deep_input\") # another 6 features through deep path\n",
    "hidden1 = Dense(30, activation=\"relu\")(input_B)\n",
    "hidden2 = Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = concatenate([input_A, hidden2])\n",
    "output = Dense(1, name=\"main_output\")(concat)\n",
    "model = Model(inputs=[input_A, input_B],\n",
    "                           outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 895us/step - loss: 3.1682 - val_loss: 1.1107\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 668us/step - loss: 0.9762 - val_loss: 0.8256\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 688us/step - loss: 0.7805 - val_loss: 0.7550\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 680us/step - loss: 0.7142 - val_loss: 0.7198\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 679us/step - loss: 0.6733 - val_loss: 0.6894\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 686us/step - loss: 0.6679 - val_loss: 0.6659\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 672us/step - loss: 0.6360 - val_loss: 0.6450\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 682us/step - loss: 0.6119 - val_loss: 0.6273\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 687us/step - loss: 0.5899 - val_loss: 0.6093\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 672us/step - loss: 0.5720 - val_loss: 0.5942\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 664us/step - loss: 0.5570 - val_loss: 0.5785\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 695us/step - loss: 0.5571 - val_loss: 0.5639\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 687us/step - loss: 0.5442 - val_loss: 0.5516\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 688us/step - loss: 0.5402 - val_loss: 0.5397\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 687us/step - loss: 0.4904 - val_loss: 0.5308\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 698us/step - loss: 0.4964 - val_loss: 0.5216\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 672us/step - loss: 0.4934 - val_loss: 0.5104\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 698us/step - loss: 0.4797 - val_loss: 0.5067\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 677us/step - loss: 0.4781 - val_loss: 0.4970\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 699us/step - loss: 0.4622 - val_loss: 0.4927\n",
      "162/162 [==============================] - 0s 410us/step - loss: 0.4834\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=SGD(lr=1e-3))\n",
    "\n",
    "X_train_A, X_train_B = X_train[:, :5], X_train[:, 2:]\n",
    "X_val_A, X_val_B = X_val[:, :5], X_val[:, 2:]\n",
    "X_test_A, X_test_B = X_test[:, :5], X_test[:, 2:]\n",
    "X_new_A, X_new_B = X_test_A[:3], X_test_B[:3]\n",
    "\n",
    "history = model.fit((X_train_A, X_train_B), y_train, epochs=20,\n",
    "                    validation_data=((X_val_A, X_val_B), y_val))\n",
    "mse_test = model.evaluate((X_test_A, X_test_B), y_test)\n",
    "y_pred = model.predict((X_new_A, X_new_B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scenarios when the model can have multiple outputs:\n",
    "- Scenarios like locating and identifying an object in a photo, this is both regression and classification\n",
    "- Having multiple independent tasks on the same data. e.g. one task if classiying the person's facial expression, and another task identifying if they're wearing gasses or not\n",
    "- Regularization technique (i.e. a training constraint whose objective is to reduce overfitting and thus improve the model's ability to generalize). Example is adding auxiliary inputs to ensure that the underlying pat of the netowrk learns something useful on its own, without relying on the rest of the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_A = Input(shape=[5], name=\"wide_input\")\n",
    "input_B = Input(shape=[6], name=\"deep_input\")\n",
    "hidden1 = Dense(30, activation=\"relu\")(input_B)\n",
    "hidden2 = Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = concatenate([input_A, hidden2])\n",
    "output = Dense(1, name=\"main_output\")(concat)\n",
    "aux_output = Dense(1, name=\"aux_output\")(hidden2)\n",
    "model = Model(inputs=[input_A, input_B],\n",
    "                           outputs=[output, aux_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=[\"mse\", \"mse\"], loss_weights=[0.9, 0.1], optimizer=SGD(lr=1e-3)) # one loss for each output (main_output and aux_output)\n",
    "# higher loss weight for the main_output because it is the output I care about the most. Aux output is only for regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 3.5816 - main_output_loss: 3.4632 - aux_output_loss: 4.6475 - val_loss: 1.1349 - val_main_output_loss: 0.9358 - val_aux_output_loss: 2.9265\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 755us/step - loss: 1.0269 - main_output_loss: 0.8494 - aux_output_loss: 2.6236 - val_loss: 0.8909 - val_main_output_loss: 0.7599 - val_aux_output_loss: 2.0692\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 748us/step - loss: 0.8454 - main_output_loss: 0.7274 - aux_output_loss: 1.9069 - val_loss: 0.8197 - val_main_output_loss: 0.7228 - val_aux_output_loss: 1.6917\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 752us/step - loss: 0.7731 - main_output_loss: 0.6814 - aux_output_loss: 1.5981 - val_loss: 0.7768 - val_main_output_loss: 0.6956 - val_aux_output_loss: 1.5077\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 746us/step - loss: 0.7452 - main_output_loss: 0.6640 - aux_output_loss: 1.4755 - val_loss: 0.7472 - val_main_output_loss: 0.6736 - val_aux_output_loss: 1.4095\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 755us/step - loss: 0.7114 - main_output_loss: 0.6378 - aux_output_loss: 1.3737 - val_loss: 0.7225 - val_main_output_loss: 0.6529 - val_aux_output_loss: 1.3489\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 767us/step - loss: 0.6756 - main_output_loss: 0.6021 - aux_output_loss: 1.3371 - val_loss: 0.7012 - val_main_output_loss: 0.6340 - val_aux_output_loss: 1.3063\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 760us/step - loss: 0.6873 - main_output_loss: 0.6187 - aux_output_loss: 1.3050 - val_loss: 0.6833 - val_main_output_loss: 0.6178 - val_aux_output_loss: 1.2736\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 754us/step - loss: 0.6737 - main_output_loss: 0.6021 - aux_output_loss: 1.3182 - val_loss: 0.6643 - val_main_output_loss: 0.5997 - val_aux_output_loss: 1.2453\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 764us/step - loss: 0.6406 - main_output_loss: 0.5708 - aux_output_loss: 1.2685 - val_loss: 0.6476 - val_main_output_loss: 0.5842 - val_aux_output_loss: 1.2177\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 789us/step - loss: 0.6142 - main_output_loss: 0.5495 - aux_output_loss: 1.1969 - val_loss: 0.6323 - val_main_output_loss: 0.5703 - val_aux_output_loss: 1.1899\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 778us/step - loss: 0.6027 - main_output_loss: 0.5388 - aux_output_loss: 1.1775 - val_loss: 0.6183 - val_main_output_loss: 0.5574 - val_aux_output_loss: 1.1662\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 767us/step - loss: 0.6252 - main_output_loss: 0.5629 - aux_output_loss: 1.1857 - val_loss: 0.6065 - val_main_output_loss: 0.5466 - val_aux_output_loss: 1.1463\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 780us/step - loss: 0.6124 - main_output_loss: 0.5517 - aux_output_loss: 1.1585 - val_loss: 0.5943 - val_main_output_loss: 0.5356 - val_aux_output_loss: 1.1227\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 761us/step - loss: 0.5756 - main_output_loss: 0.5118 - aux_output_loss: 1.1490 - val_loss: 0.5842 - val_main_output_loss: 0.5266 - val_aux_output_loss: 1.1026\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 764us/step - loss: 0.5601 - main_output_loss: 0.5003 - aux_output_loss: 1.0990 - val_loss: 0.5743 - val_main_output_loss: 0.5178 - val_aux_output_loss: 1.0828\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 756us/step - loss: 0.5552 - main_output_loss: 0.4961 - aux_output_loss: 1.0873 - val_loss: 0.5647 - val_main_output_loss: 0.5095 - val_aux_output_loss: 1.0609\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 772us/step - loss: 0.5586 - main_output_loss: 0.5011 - aux_output_loss: 1.0757 - val_loss: 0.5560 - val_main_output_loss: 0.5018 - val_aux_output_loss: 1.0442\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 789us/step - loss: 0.5183 - main_output_loss: 0.4628 - aux_output_loss: 1.0174 - val_loss: 0.5485 - val_main_output_loss: 0.4955 - val_aux_output_loss: 1.0251\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 774us/step - loss: 0.5257 - main_output_loss: 0.4710 - aux_output_loss: 1.0182 - val_loss: 0.5421 - val_main_output_loss: 0.4903 - val_aux_output_loss: 1.0086\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([X_train_A, X_train_B], [y_train, y_train], epochs=20,\n",
    "                    validation_data=([X_val_A, X_val_B], [y_val, y_val]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 477us/step - loss: 0.5606 - main_output_loss: 0.5018 - aux_output_loss: 1.0892\n"
     ]
    }
   ],
   "source": [
    "total_loss, main_loss, aux_loss = model.evaluate([X_test_A, X_test_B], [y_test, y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_main, y_pred_aux = model.predict([X_test_A, X_test_B])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
