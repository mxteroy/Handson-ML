{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "train_data = pd.read_csv(\"./datasets/train.csv\")\n",
    "x_test_df = pd.read_csv(\"./datasets/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_df_full, y_train_df_full = train_data.loc[:, train_data.columns != \"SalePrice\"], train_data.loc[:, \"SalePrice\"]\n",
    "\n",
    "\n",
    "x_train_ids = x_train_df_full['Id']\n",
    "x_test_ids = x_test_df['Id']\n",
    "columns_to_drop = ['Id', 'PoolQC', 'Alley', 'MiscFeature']\n",
    "x_train_df_full = x_train_df_full.drop(columns=columns_to_drop)\n",
    "x_test_df = x_test_df.drop(columns=columns_to_drop)\n",
    "\n",
    "print( x_test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_attribs = x_train_df_full.select_dtypes(np.number).columns.tolist()\n",
    "cat_attribs = x_train_df_full.select_dtypes('object').columns.tolist()\n",
    "# print(x_train_full[cat_attribs].info(), x_test[cat_attribs].info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train_full[cat_attribs] = x_train_full[cat_attribs].apply(lambda x: x.fillna(x.value_counts().index[0]))\n",
    "# x_test[cat_attribs] = x_test[cat_attribs].apply(lambda x: x.fillna(x.value_counts().index[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, OrdinalEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class MostFrequentImputer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        self.most_frequent_ = pd.Series([X[c].value_counts().index[0] for c in X], index=X.columns)\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        return X.fillna(self.most_frequent_)\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "    ('scaler', StandardScaler()), #scale the data using the dataset w/o nums\n",
    "])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "    ('imputer', MostFrequentImputer()),\n",
    "    ('labels', OrdinalEncoder()),\n",
    "    #('cat',  OneHotEncoder(sparse=False)) #one-hot encode the columns in the dataset\n",
    "])\n",
    "\n",
    "def get_prepared_data():\n",
    "    return ColumnTransformer(transformers=[\n",
    "        ('num', num_pipeline, num_attribs),\n",
    "        ('cat', cat_pipeline, cat_attribs) #one-hot encode the columns in the dataset\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_full_prepared = get_prepared_data().fit_transform(x_train_df_full)\n",
    "x_test = get_prepared_data().fit_transform(x_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def get_prepared_train_val(train_data, train_labels):\n",
    "    x_train, x_val, y_train, y_val = train_test_split(train_data, train_labels, test_size=0.25)\n",
    "    y_train = list(y_train)\n",
    "    y_val = list(y_val)\n",
    "    return x_train, x_val, y_train, y_val\n",
    "\n",
    "x_train, x_val, y_train, y_val = get_prepared_train_val(x_train_full_prepared, y_train_df_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "randf_reg = RandomForestRegressor()\n",
    "\n",
    "randf_reg.fit(x_train, y_train)\n",
    "randf_reg.score(x_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randf_reg.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop the unimportant features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances_cols = sorted(zip(randf_reg.feature_importances_, num_attribs + cat_attribs), reverse=True)\n",
    "unimportant_cols = [col_name for _, col_name in importances_cols[len(importances_cols)//2+4:]]\n",
    "importances_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_df_full.drop(columns=unimportant_cols, inplace=True)\n",
    "x_test_df.drop(columns=unimportant_cols, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_attribs = x_train_df_full.select_dtypes(np.number).columns.tolist()\n",
    "cat_attribs = x_train_df_full.select_dtypes('object').columns.tolist()\n",
    "x_train_full_prepared = get_prepared_data().fit_transform(x_train_df_full)\n",
    "x_test = get_prepared_data().fit_transform(x_test_df)\n",
    "x_train, x_val, y_train, y_val = get_prepared_train_val(x_train_full_prepared, y_train_df_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "params = [\n",
    "    {'n_estimators': np.arange(200, 300, 5)},\n",
    "]\n",
    "\n",
    "grid_searcher = RandomizedSearchCV(RandomForestRegressor(), params, n_iter=30, cv=3, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid_searcher.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid_searcher.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = grid_searcher.best_estimator_\n",
    "model = RandomForestRegressor(n_estimators=230)\n",
    "model.fit(x_train, y_train)\n",
    "model.score(x_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame({'Id': x_test_ids, 'SalePrice': model.predict(x_test)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.to_csv('random_forest_out.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "svr = SVR()\n",
    "svr.fit(x_train, y_train)\n",
    "\n",
    "mean_squared_error(y_val, svr.predict(x_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca_reducer = PCA(n_components=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_new = pca_reducer.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_reg = LogisticRegression(max_iter=10000)\n",
    "log_reg.fit(x_train, y_train)\n",
    "log_reg.score(x_val, y_val)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res = pd.DataFrame({'Id': x_test_ids, 'SalePrice': log_reg.predict(x_test)})\n",
    "# res.to_csv('log_reg_out.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "gb_reg = GradientBoostingRegressor()\n",
    "gb_reg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_reg.score(x_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame({'Id': x_test_ids, 'SalePrice': gb_reg.predict(x_test)})\n",
    "res.to_csv('gb_reg_out.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingRegressor\n",
    "\n",
    "voting_reg = VotingRegressor(estimators=[('rand forest', model),  ('gradient boost reg', gb_reg)])\n",
    "voting_reg.fit(x_train, y_train)\n",
    "voting_reg.score(x_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame({'Id': x_test_ids, 'SalePrice': voting_reg.predict(x_test)})\n",
    "res.to_csv('voting_reg_out.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Boosting Regression seems to give the best output with a RMSE log error of 0.14485. I'll hyperparameter tune it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {'learning_rate': [0.008, 0.01, 0.012],\n",
    "                  'n_estimators' : [550, 600, 650],\n",
    "                 }\n",
    "\n",
    "grid_searcher = GridSearchCV(GradientBoostingRegressor(subsample=0.1, max_depth=8), param_grid=params, cv=3, verbose=1)\n",
    "# grid_searcher.fit(x_train, y_train)\n",
    "grid_searcher.fit(x_train_full_prepared, list(y_train_df_full))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame({'Id': x_test_ids, 'SalePrice': grid_searcher.best_estimator_.predict(x_test)})\n",
    "res.to_csv('gb_reg_tuned_out.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_searcher.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_gb_reg = GradientBoostingRegressor(subsample=0.1, max_depth=8, n_estimators=580, learning_rate=0.01)\n",
    "tuned_gb_reg.fit(x_train_full_prepared, list(y_train_df_full))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_randf_reg =  RandomForestRegressor(n_estimators=200)\n",
    "tuned_randf_reg.fit(x_train_full_prepared, list(y_train_df_full))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingRegressor\n",
    "\n",
    "voting_reg = VotingRegressor(estimators=[('rand forest', tuned_randf_reg),  ('gradient boost reg', tuned_gb_reg)])\n",
    "voting_reg.fit(x_train_full_prepared, list(y_train_df_full))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame({'Id': x_test_ids, 'SalePrice': voting_reg.predict(x_test)})\n",
    "res.to_csv('voting_reg_tuned_rfreg_gbreg_out.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
